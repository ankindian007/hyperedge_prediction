% This is "sig-alternate.tex" V2.0 May 2012
% This file should be compiled with V2.5 of "sig-alternate.cls" May 2012
%
% This example file demonstrates the use of the 'sig-alternate.cls'
% V2.5 LaTeX2e document class file. It is for those submitting
% articles to ACM Conference Proceedings WHO DO NOT WISH TO
% STRICTLY ADHERE TO THE SIGS (PUBS-BOARD-ENDORSED) STYLE.
% The 'sig-alternate.cls' file will produce a similar-looking,
% albeit, 'tighter' paper resulting in, invariably, fewer pages.
%
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V2.5) produces:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) NO page numbers
%
% as against the acm_proc_article-sp.cls file which
% DOES NOT produce 1) thru' 3) above.
%
% Using 'sig-alternate.cls' you have control, however, from within
% the source .tex file, over both the CopyrightYear
% (defaulted to 200X) and the ACM Copyright Data
% (defaulted to X-XXXXX-XX-X/XX/XX).
% e.g.
% \CopyrightYear{2007} will cause 2007 to appear in the copyright line.
% \crdata{0-12345-67-8/90/12} will cause 0-12345-67-8/90/12 to appear in the copyright line.
%
% ---------------------------------------------------------------------------------------------------------------
% This .tex source is an example which *does* use
% the .bib file (from which the .bbl file % is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission, you *NEED* to 'insert'
% your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% ================= IF YOU HAVE QUESTIONS =======================
% Questions regarding the SIGS styles, SIGS policies and
% procedures, Conferences etc. should be sent to
% Adrienne Griscti (griscti@acm.org)
%
% Technical questions _only_ to
% Gerald Murray (murray@hq.acm.org)
% ===============================================================
%
% For tracking purposes - this is V2.0 - May 2012

\documentclass{sig-alternate}
\usepackage{amsmath}
\DeclareMathOperator*{\argmin}{arg\,min}


\begin{document}
%
% --- Author Metadata here ---
\conferenceinfo{WOODSTOCK}{'97 El Paso, Texas USA}
%\CopyrightYear{2007} % Allows default copyright year (20XX) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
% --- End of Author Metadata ---

\title{Higher Order Group Prediction}

%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{8} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
%\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
%\alignauthor
%Ben Trovato\titlenote{Dr.~Trovato insisted his name be first.}\\
 %      \affaddr{Institute for Clarity in Documentation}\\
  %     \affaddr{1932 Wallamaloo Lane}\\
   %    \affaddr{Wallamaloo, New Zealand}\\
     %  \email{trovato@corporation.com}
% 2nd. author

%}
% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
%\additionalauthors{Additional authors: John Smith (The Th{\o}rv{\"a}ld Group,
%email: {\texttt{jsmith@affiliation.org}}) and Julius P.~Kumquat
%(The Kumquat Consortium, email: {\texttt{jpkumquat@consortium.net}}).}
%\date{30 July 1999}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}
Aim is to predict higher order groups given a previous group interaction history.
\end{abstract}

% A category with the (minimum) three required fields
%\category{H.4}{Information Systems Applications}{Miscellaneous}
%A category including the fourth, optional field follows...
%\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]

\terms{Hyperedge, Hypergraph}

\keywords{Hyperedge Prediction, Hypergraphs, Convex Optimization}

\section{Problem Statement}

Our input is the history of previous collaborations, $\mathbf{Y}=\{\mathbf{y_{1}},\mathbf{y_{2}}, ..., \mathbf{y_{(T-1)}} \}$. Here, each $\mathbf{y_{t}}=\{v_1,v_2, ....., v_k\}$ represents a particular hyperedge (group or collaboration) that occurs at time instance $t$ with the given vertices each represented by $v_i$ (total number of vertices being $n$). Our aim is to predict the possible new hyperedge $\mathbf{y_{new}}$ that occurs at $t=T$.

\section{Approach 1}

We treat this problem as an optimization task of finding the vector $\mathbf{y_{new}}$ which is nearest to all the given previous collaboration vectors $\mathbf{y_i}$, $i \in \{1,2,.....,(T-1)\}$ and is also sparse. We define the following regularization framework:

\begin{equation}
\argmin_{\mathbf{y_{new}}}   \mathbf{Dist(Y,y_{new})} + \lambda \| \mathbf{y_{new}} \|_{1}
\end{equation}

where $\mathbf{Dist(Y,y_{new})}$ represents the distance of different kinds like euclidean distance $\| \mathbf{Y}-\mathbf{1y_{new}^T} \|_2$, hamming distance etc. and $\mathbf{1}$ is a vector of all ones. The second term is lasso constraint for sparsity. The parameter $\lambda$ is used for tuning the extent of regularization.

\section{Approach 2}

We treat this problem as an optimization task of finding the stack of vectors $\mathbf{Y_{new} = [y_{new}^{1},...,y_{new}^{P}]^{T}}$ which is nearest to all the given previous collaboration vectors $\mathbf{y_i}$, $i \in \{1,2,.....,(T-1)\}$ and is also sparse. We define the following regularization framework:

\begin{equation}
\argmin_{\mathbf{Y_{new}}}   \sum_{p=1}^{P}  \sum_{t=1}^{T-1} \mathbf{Dist(y_t,y_{new}^{p})} + \lambda \sum_{p=1}^{P} \| \mathbf{y_{new}^{p}} \|_{1}
\end{equation}

where $\mathbf{Dist(y_t,y_{new}^{p})}$ represents the distance of different kinds like euclidean distance $\| \mathbf{y_t}-\mathbf{y_{new}^{p}} \|_2$, hamming distance etc. The second term is lasso constraint for sparsity. The parameter $\lambda$ is used for tuning the extent of regularization. If we add diversity in the set of group obtained by regularizing the covariance matrix then we obtain:

\begin{equation}
\argmin_{\mathbf{Y_{new}}}   \sum_{p=1}^{P}  \sum_{t=1}^{T-1} \mathbf{Dist(y_t,y_{new}^{p})} + \lambda_1 \sum_{p=1}^{P} \| \mathbf{y_{new}^{p}} \|_{1} + \lambda_2 \| \mathbf{Y_{new}Y_{new}^{T}}\|_2
\end{equation}

We do not see any easy way to deal with the third (co-variance) term while taking the gradient. Therefore, another method is to iteratively run the optimization for each of the $\mathbf{y_{new}^{p}}$ and modify the minimized function by adding constraint of diversity from the previous predictions. Following is the method:


\begin{multline}
\argmin_{\mathbf{y_{new}^{p}}}   \sum_{t=1}^{T-1} \mathbf{Dist(y_t,y_{new}^{p})} + \lambda_1 \| \mathbf{y_{new}^{p}} \|_{1} \\ + \lambda_2 \mathbf{exp} \left\{ - \sum_{j}^{\mathbf{p}-1} \mathbf{Dist(y_{new}^{p},y_{new}^{j})} \right\}
\end{multline}


for the $\mathbf{p}^{th}$ prediction. For $\mathbf{p}=1$, the third term is zero. Third term decreases as the distance between the new prediction and the previous prediction increases. This convex term therefore, should take care of diversity needed. (\textbf{Is there a better way for diversity modeling or is there a straightforward way of dealing with the gradient for Covariance term in (3) ?})

\section{Approach 3}

\textbf{Approach 1} is static in the sense that it does not take into account the time dimension. Moreover, \textbf{Approach 1} assumes an oversimplified and over demanding in the sense that it wants to find out new groups which are similar to the whole stack of groups observed in past. Rather, a more realistic approach should consider vectors (groups or hyperedges) that are similar to some subset of previously observed groups. Moreover, it is safe to assume that these subsets are the various communities or clusters of related hyperedges observed in past. We therefore, represent the previous collaboration vectors $\mathbf{y_{ic}}$, $i \in \{1,2,.....,(T-1)\}$ and $c \in \{1,2,...,N_c\}$ ($N_c$ being the total number of communities observed in past). We define the following regularization framework:

\begin{equation}
\argmin_{\mathbf{Y_{new}}}  \sum_{p=1}^{P} \sum_{t=1}^{T-1} \gamma^{-t} \mathbf{Dist(y_{tc},y_{new}^{p})} + \lambda  \sum_{p=1}^{P} \| \mathbf{y_{new}^{p}} \|_{1}
\end{equation}

where $\mathbf{Dist(y_{tc},y_{new}^{p})}$ represents the distance of different kinds like euclidean distance $\| \mathbf{y_{tc}}-\mathbf{1(y_{new}^{P})^T} \|_2$, hamming distance etc, $p$ is the index of the new vectors predicted for each community, and $\mathbf{1}$ is a vector of all ones. The second term is lasso constraint for sparsity. The parameter $\lambda$ is used for tuning the extent of regularization and parameter $\gamma$ penalizes more if the predicted hyperedge is not similar to hyperedges in recent past. Community $c$ for $\mathbf{y_{tc}}$ is decided using any clustering methods like KMeans, or columns of a Dictionary. Adding diversity results in :

\begin{equation}
\argmin_{\mathbf{Y_{new}}}  \sum_{p=1}^{P} \sum_{t=1}^{T-1} \gamma^{-t} \mathbf{Dist(y_{tc},y_{new}^{p})} + \lambda_1  \sum_{p=1}^{P} \| \mathbf{y_{new}^{p}} \|_{1} + \lambda_2 \| \mathbf{Y_{new}Y_{new}^{T}}\|_2
\end{equation}


\section{Issues}

\begin{itemize}
\item{ Is this a reasonable approach to take ? Or there is some trivial issue with it ?,} 
\item {We can measure distance from the cluster centers rather than the $\mathbf{y_{tc}}$ directly. More generally we can take distance from a dictionary representing $\mathbf{Y}$.}
\end{itemize}


%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{sigproc}  % sigproc.bib is the name of the Bibliography in this case


\end{document}
